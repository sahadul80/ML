{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XjcjpclKg-d",
        "outputId": "1eba8a86-e41c-4e68-cf3d-9a862da3d365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has apparently already been downloaded and unpacked.\n",
            "Training data shape: (50000, 32, 32, 3)\n",
            "Training labels shape: (50000,)\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Test labels shape: (10000,)\n",
            "(1000, 3072) (100, 3072)\n",
            "Got 24 / 100 correct with k=5 => accuracy: 0.240000\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "def _print_download_progress(count, block_size, total_size):\n",
        "    pct_complete = float(count * block_size) / total_size\n",
        "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
        "    sys.stdout.write(msg)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def maybe_download_and_extract(url, download_dir):\n",
        "    filename = url.split('/')[-1]\n",
        "    file_path = os.path.join(download_dir, filename)\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "\n",
        "        file_path, _ = urllib.request.urlretrieve(url=url,\n",
        "                                                  filename=file_path,\n",
        "                                                  reporthook=_print_download_progress)\n",
        "\n",
        "        print()\n",
        "        print(\"Download finished. Extracting files.\")\n",
        "\n",
        "        if file_path.endswith(\".zip\"):\n",
        "            zipfile.ZipFile(file=file_path, mode=\"r\").extractall(download_dir)\n",
        "        elif file_path.endswith((\".tar.gz\", \".tgz\")):\n",
        "            tarfile.open(name=file_path, mode=\"r:gz\").extractall(download_dir)\n",
        "\n",
        "        print(\"Done.\")\n",
        "    else:\n",
        "        print(\"Data has apparently already been downloaded and unpacked.\")\n",
        "\n",
        "def load_pickle(f):\n",
        "    return pickle.load(f, encoding='latin1')\n",
        "\n",
        "def load_CIFAR_batch(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = load_pickle(f)\n",
        "        X = datadict['data']\n",
        "        Y = datadict['labels']\n",
        "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
        "        Y = np.array(Y)\n",
        "        return X, Y\n",
        "\n",
        "def load_CIFAR10(ROOT):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for b in range(1,6):\n",
        "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
        "        X, Y = load_CIFAR_batch(f)\n",
        "        xs.append(X)\n",
        "        ys.append(Y)\n",
        "    Xtr = np.concatenate(xs)\n",
        "    Ytr = np.concatenate(ys)\n",
        "    del X, Y\n",
        "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
        "    return Xtr, Ytr, Xte, Yte\n",
        "\n",
        "class KNearestNeighbor(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X, k=1, num_loops=0):\n",
        "        if num_loops == 0:\n",
        "            dists = self.compute_distances(X)\n",
        "        else:\n",
        "            raise ValueError('Invalid value %d for num_loops' % num_loops)\n",
        "        return self.predict_labels(dists, k=k)\n",
        "\n",
        "    def compute_distances(self, X, distance_metric='euclidean'):\n",
        "        num_test = X.shape[0]\n",
        "        num_train = self.X_train.shape[0]\n",
        "        dists = np.zeros((num_test, num_train))\n",
        "        if distance_metric == 'euclidean':\n",
        "            for i in range(num_test):\n",
        "                dists[i, :] = np.sqrt(np.sum((self.X_train - X[i, :])**2, axis=1))\n",
        "        elif distance_metric == 'manhattan':\n",
        "            for i in range(num_test):\n",
        "                dists[i, :] = np.sum(np.abs(self.X_train - X[i, :]), axis=1)\n",
        "        else:\n",
        "            raise ValueError('Invalid distance_metric.')\n",
        "        return dists\n",
        "\n",
        "    def predict_labels(self, dists, k=1):\n",
        "        num_test = dists.shape[0]\n",
        "        y_pred = np.zeros(num_test)\n",
        "        for i in range(num_test):\n",
        "            closest_y = []\n",
        "            sorted_indices = np.argsort(dists[i, :])\n",
        "            closest_y = self.y_train[sorted_indices[:k]]\n",
        "            counts = np.bincount(closest_y)\n",
        "            y_pred[i] = np.argmax(counts)\n",
        "        return y_pred\n",
        "\n",
        "def visualize_data(X_train, y_train):\n",
        "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    num_classes = len(classes)\n",
        "    samples_per_class = 7\n",
        "    for y, cls in enumerate(classes):\n",
        "        idxs = np.flatnonzero(y_train == y)\n",
        "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "        for i, idx in enumerate(idxs):\n",
        "            plt_idx = i * num_classes + y + 1\n",
        "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "            plt.imshow(X_train[idx].astype('uint8'))\n",
        "            plt.axis('off')\n",
        "            if i == 0:\n",
        "                plt.title(cls)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Download CIFAR10 data and store it in the current directory if you have not done it.\n",
        "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    download_dir = \"./data\"\n",
        "    maybe_download_and_extract(url, download_dir)\n",
        "\n",
        "    # Load training and testing data from CIFAR10 dataset\n",
        "    cifar10_dir = './data/cifar-10-batches-py'\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "\n",
        "    # Checking the size of the training and testing data\n",
        "    print('Training data shape:', X_train.shape)\n",
        "    print('Training labels shape:', y_train.shape)\n",
        "    print('Test data shape:', X_test.shape)\n",
        "    print('Test labels shape:', y_test.shape)\n",
        "\n",
        "    # Visualize the data if you want\n",
        "    # visualize_data(X_train, y_train)\n",
        "\n",
        "    # Memory error prevention by subsampling data. We sample 1000 training examples and 100 test examples.\n",
        "    num_training = 1000\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "\n",
        "    num_test = 100\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Reshape data and place into rows. Flatten the training and test data so each row\n",
        "    # consists of all pixels of an example\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "    print(X_train.shape, X_test.shape) # X_train should be (10000, 3072) and X_test should be (1000, 3072)\n",
        "\n",
        "    # Performing KNN\n",
        "    classifier = KNearestNeighbor()\n",
        "\n",
        "    # Use the KNearestNeighbour classifier to do as follows:\n",
        "    # 1) Initialize classifier with training data\n",
        "    # 2) Use classifier to compute distances from each test example in X_test to every training example\n",
        "    # 3) Use classifier to predict labels of each test example in X_test using k=5\n",
        "    # Initialize classifier with training data\n",
        "    classifier.train(X_train, y_train)\n",
        "    dists = classifier.compute_distances(X_test)\n",
        "    k = 5\n",
        "    y_test_pred = classifier.predict_labels(dists, k)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    num_correct = np.sum(y_test_pred == y_test)  # number of test examples correctly predicted\n",
        "    accuracy = float(num_correct) / num_test\n",
        "    print('Got %d / %d correct with k=%d => accuracy: %f' % (num_correct, num_test, k, accuracy))\n"
      ]
    }
  ]
}